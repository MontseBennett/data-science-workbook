{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "import_from_internet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIBnmy_86Gkg",
        "colab_type": "text"
      },
      "source": [
        "# Importing data from the Internet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRPzK7xDEuDz",
        "colab_type": "text"
      },
      "source": [
        "## Importing flat files from the web: your turn!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwu9zEQ9E5jS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import package\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "# Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Assign url of file: url\n",
        "url = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
        "\n",
        "# Save file locally\n",
        "urlretrieve(url, 'winequality-red.csv')\n",
        "\n",
        "# Read file into a DataFrame and print its head\n",
        "df = pd.read_csv('winequality-red.csv', sep=';')\n",
        "print(df.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eks41nPnFeIR",
        "colab_type": "text"
      },
      "source": [
        "## Opening and reading flat files from the web"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxXpY7QZFePu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import packages\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Assign url of file: url\n",
        "url = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
        "\n",
        "# Read file into a DataFrame: df\n",
        "df = pd.read_csv(url, sep=';')\n",
        "\n",
        "# Print the head of the DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Plot first column of df\n",
        "pd.DataFrame.hist(df.ix[:, 0:1])\n",
        "plt.xlabel('fixed acidity (g(tartaric acid)/dm$^3$)')\n",
        "plt.ylabel('count')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1rTW7SOFz-_",
        "colab_type": "text"
      },
      "source": [
        "## Importing non-flat files from the web"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvMgT2qQF0Uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import package\n",
        "import pandas as pd\n",
        "\n",
        "# Assign url of file: url\n",
        "url = 'http://s3.amazonaws.com/assets.datacamp.com/course/importing_data_into_r/latitude.xls'\n",
        "\n",
        "# Read in all sheets of Excel file: xls\n",
        "xls = pd.read_excel(url, sheet_name=None)\n",
        "\n",
        "# Print the sheetnames to the shell\n",
        "print(xls.keys())\n",
        "\n",
        "# Print the head of the first sheet (using its name, NOT its index)\n",
        "print(xls['1700'].head())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS5k8on6Hzsc",
        "colab_type": "text"
      },
      "source": [
        "## Performing HTTP requests in Python using urllib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmd39dOzH0DS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import packages\n",
        "from urllib.request import Request, urlopen\n",
        "\n",
        "# Specify the url\n",
        "url = \"http://www.datacamp.com/teach/documentation\"\n",
        "\n",
        "# This packages the request: request\n",
        "request = Request(url) \n",
        "\n",
        "# Sends the request and catches the response: response\n",
        "response = urlopen(request)\n",
        "\n",
        "# Print the datatype of response\n",
        "print(type(response))\n",
        "\n",
        "# Be polite and close the response!\n",
        "response.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-zRFdkXIOWd",
        "colab_type": "text"
      },
      "source": [
        "## Printing HTTP request results in Python using urllib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QtQ2KHuIPBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import packages\n",
        "from urllib.request import urlopen, Request\n",
        "\n",
        "# Specify the url\n",
        "url = \"http://www.datacamp.com/teach/documentation\"\n",
        "\n",
        "# This packages the request\n",
        "request = Request(url)\n",
        "\n",
        "# Sends the request and catches the response: response\n",
        "response = urlopen(request)\n",
        "\n",
        "# Extract the response: html\n",
        "html = response.read()\n",
        "\n",
        "# Print the html\n",
        "print(html)\n",
        "\n",
        "# Be polite and close the response!\n",
        "response.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myYuMPRoIiz7",
        "colab_type": "text"
      },
      "source": [
        "## Performing HTTP requests in Python using requests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkQ59j-7IjN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import package\n",
        "import requests\n",
        "\n",
        "# Specify the url: url\n",
        "url = \"http://www.datacamp.com/teach/documentation\"\n",
        "\n",
        "# Packages the request, send the request and catch the response: r\n",
        "r = requests.get(url)\n",
        "\n",
        "# Extract the response: text\n",
        "text = r.text\n",
        "\n",
        "# Print the html\n",
        "print(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb3qB7Z2JgzN",
        "colab_type": "text"
      },
      "source": [
        "## Parsing HTML with BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_WFrEVnJhIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import packages\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Specify url: url\n",
        "url = url = 'https://www.python.org/~guido/'\n",
        "\n",
        "# Package the request, send the request and catch the response: r\n",
        "r = requests.get(url)\n",
        "\n",
        "# Extracts the response as html: html_doc\n",
        "html_doc = r.text\n",
        "\n",
        "# Create a BeautifulSoup object from the HTML: soup\n",
        "soup = BeautifulSoup(html_doc)\n",
        "\n",
        "# Prettify the BeautifulSoup object: pretty_soup\n",
        "pretty_soup = soup.prettify()\n",
        "\n",
        "# Print the response\n",
        "print(pretty_soup)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdE43BOkJ_UY",
        "colab_type": "text"
      },
      "source": [
        "## Turning a webpage into data using BeautifulSoup: getting the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6iTZErzKAEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import packages\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Specify url: url\n",
        "url = 'https://www.python.org/~guido/'\n",
        "\n",
        "# Package the request, send the request and catch the response: r\n",
        "r = requests.get(url)\n",
        "\n",
        "# Extract the response as html: html_doc\n",
        "html_doc = r.text\n",
        "\n",
        "# Create a BeautifulSoup object from the HTML: soup\n",
        "soup = BeautifulSoup(html_doc)\n",
        "\n",
        "# Get the title of Guido's webpage: guido_title\n",
        "guido_title = soup.title\n",
        "\n",
        "# Print the title of Guido's webpage to the shell\n",
        "print(guido_title)\n",
        "\n",
        "# Get Guido's text: guido_text\n",
        "guido_text = soup.text\n",
        "\n",
        "# Print Guido's text to the shell\n",
        "print(guido_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzcnOCcsKVjp",
        "colab_type": "text"
      },
      "source": [
        "## Turning a webpage into data using BeautifulSoup: getting the hyperlinks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZkk9ZdsKV6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import packages\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Specify url\n",
        "url = 'https://www.python.org/~guido/'\n",
        "\n",
        "# Package the request, send the request and catch the response: r\n",
        "r = requests.get(url)\n",
        "\n",
        "# Extracts the response as html: html_doc\n",
        "html_doc = r.text\n",
        "\n",
        "# create a BeautifulSoup object from the HTML: soup\n",
        "soup = BeautifulSoup(html_doc)\n",
        "\n",
        "# Print the title of Guido's webpage\n",
        "print(soup.title)\n",
        "\n",
        "# Find all 'a' tags (which define hyperlinks): a_tags\n",
        "a_tags = soup.find_all('a')\n",
        "\n",
        "# Print the URLs to the shell\n",
        "for link in a_tags:\n",
        "    print(link.get('href'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}